# Req2Run Benchmark

[English](#english) | [æ—¥æœ¬èª](#japanese)

---

<a id="english"></a>
## English

**A comprehensive benchmark framework for evaluating AI code generation systems from requirements to running code**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/itdojp/req2run-benchmark)
[![Status](https://img.shields.io/badge/status-active-green.svg)]()

### Overview

Req2Run (Requirements to Running Code) is a benchmark framework for quantitatively evaluating the implementation capabilities of AI/LLM systems. It generates working code from detailed requirement specifications and performs automated evaluation.

### Features

- ğŸ¯ **Comprehensive Problem Set**: 35 problems across 16+ categories including Web APIs, cryptography, network protocols, data processing
- ğŸ¤– **Fully Automated Evaluation**: Execution from generation to evaluation without human intervention
- ğŸ“Š **Quantitative Metrics**: Measures functional coverage, performance, security, and code quality
- ğŸ”§ **Standardized Environment**: Unified execution environment on Docker/Kubernetes
- ğŸ“ˆ **Difficulty Levels**: Four levels - Basic (1), Intermediate (8), Advanced (17), Expert (9)
- ğŸŒ **Full Internationalization**: Complete documentation available in English and Japanese

### Quick Start

#### Prerequisites

- Python 3.9+ (3.11 recommended)
- Docker 24.0+ (optional but recommended)
- Git

#### Environment Setup

```bash
# Clone the repository
git clone https://github.com/itdojp/req2run-benchmark.git
cd req2run-benchmark

# Quick setup with helper script
# Linux/Mac:
./scripts/setup-env.sh

# Windows PowerShell:
.\scripts\setup-env.ps1

# Windows CMD:
scripts\setup-env.bat
```

For detailed setup instructions, see [Environment Setup Guide](docs/ENVIRONMENT_SETUP.md).

#### Using Docker (Recommended)

```bash
# Build Docker image with all dependencies
docker build -t req2run-benchmark .

# Run in Docker container
docker run -it -v $(pwd):/workspace req2run-benchmark bash

# Or use docker-compose for development
docker-compose -f docker-compose.dev.yml up
```

#### Manual Installation

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate.bat  # Windows

# Install dependencies
pip install -r requirements.txt
```

If you encounter dependency issues, see [Dependency Troubleshooting Guide](docs/DEPENDENCY_TROUBLESHOOTING.md).

#### Basic Usage

```bash
# Evaluate a single problem
python -m req2run evaluate --problem WEB-001 --submission ./submissions/my_solution

# Run batch evaluation
python -m req2run batch-evaluate --difficulty intermediate --output ./results

# Generate report
python -m req2run report --results ./results --format html
```

### Problem Categories

| Category | Description | Count |
|----------|-------------|-------|
| `web_api` | RESTful APIs, GraphQL, WebSockets | 7 |
| `database` | In-memory, time-series, event sourcing | 4 |
| `cli_tool` | CLI tools, TUI dashboards, job orchestrators | 3 |
| `network_protocol` | TCP/UDP, reverse proxy, gRPC | 3 |
| `cryptography` | Encryption, ZKP, homomorphic | 3 |
| `data_processing` | Stream processing, ETL, CDC | 3 |
| `authentication` | OAuth, RBAC/ABAC | 2 |
| `machine_learning` | ML pipelines with serving | 1 |
| `language_processor` | SQL interpreter | 1 |
| `real_time_communication` | WebRTC video conferencing | 1 |
| `blockchain` | Smart contract platform | 1 |
| `orchestration` | Container orchestration | 1 |
| `api_gateway` | GraphQL federation | 1 |
| `runtime_platform` | Serverless runtime | 1 |
| `service_mesh` | Service mesh control plane | 1 |
| `observability` | OpenTelemetry tracing | 1 |

### Evaluation Flow

```mermaid
graph LR
    A[Requirements] --> B[AI Generation]
    B --> C[Build]
    C --> D[Deploy]
    D --> E[Test Execution]
    E --> F[Metrics Collection]
    F --> G[Score Calculation]
    G --> H[Report]
```

### Directory Structure

```
req2run-benchmark/
â”œâ”€â”€ problems/           # Problem definitions (YAML)
â”‚   â”œâ”€â”€ basic/         # Basic level problems
â”‚   â”œâ”€â”€ intermediate/  # Intermediate level problems
â”‚   â”œâ”€â”€ advanced/      # Advanced level problems
â”‚   â””â”€â”€ expert/        # Expert level problems
â”œâ”€â”€ evaluation/        # Evaluation framework
â”‚   â”œâ”€â”€ harness/      # Test harness
â”‚   â”œâ”€â”€ metrics/      # Metrics calculation
â”‚   â””â”€â”€ reports/      # Report generation
â”œâ”€â”€ infrastructure/    # Infrastructure configs
â”‚   â”œâ”€â”€ docker/       # Docker containers
â”‚   â”œâ”€â”€ kubernetes/   # K8s manifests
â”‚   â””â”€â”€ terraform/    # IaC configurations
â”œâ”€â”€ scripts/          # Utility scripts
â”œâ”€â”€ tests/            # Test suite
â””â”€â”€ docs/             # Documentation
```

### Evaluation Criteria

Each problem is evaluated based on:

- **Functional Coverage** (30-40%)
- **Test Pass Rate** (20-30%)
- **Performance** (10-20%)
- **Code Quality** (10-20%)
- **Security** (10-20%)

Pass Criteria: Total Score â‰¥ 70%

### API Usage

```python
from req2run import Evaluator, Problem

# Load problem
problem = Problem.load("WEB-001")

# Initialize evaluator
evaluator = Evaluator(
    problem=problem,
    environment="docker",
    timeout=3600
)

# Run evaluation
result = evaluator.evaluate(
    submission_path="./my_solution",
    verbose=True
)

# Get results
print(f"Score: {result.score}")
print(f"Status: {result.status}")
```

### How Req2Run Differs from Other Benchmarks

> **Req2Run** evaluates *requirements-to-running-code* with **functional + non-functional (performance/security/quality)** metrics in a **unified containerized environment**, complementing function-level benchmarks (HumanEval/MBPP) and code modification benchmarks (SWE-bench).

#### Detailed Comparison

| Benchmark | Focus | Primary Metric | Req2Run Distinction |
|-----------|-------|----------------|--------------------|
| **HumanEval/MBPP** | Function-level coding | Pass@k | Full application + NFR evaluation |
| **SWE-bench** | Issue resolution in repos | %Resolved | New implementation from requirements |
| **EvalPlus** | Test robustness | Enhanced Pass@k | Production deployment readiness |
| **MultiPL-E** | Multi-language | Cross-language Pass@k | Container-based deployment |
| **ArchCode** | Design quality | NFR compliance | Comprehensive NFR scoring |
| **HumanEval-V** | Visual programming | Pass@k with images | Text-based requirements only |

#### Key Differentiators

1. **Requirements-First Approach**: Uses RFC 2119 (MUST/SHOULD/MAY) and EARS syntax for precise requirement specification
2. **Production Readiness**: Evaluates not just correctness but deployment readiness with Docker/Kubernetes
3. **Comprehensive NFR Evaluation**: 
   - Performance: P95/P99 latency, throughput, resource usage
   - Security: Static analysis (Bandit/Semgrep) + runtime sandboxing (nsjail/firejail)
   - Quality: Complexity, coverage, maintainability, documentation
4. **Cost Efficiency Metrics**: Score-per-dollar and score-per-token calculations
5. **Test Augmentation**: Following EvalPlus methodology with property-based and boundary testing
6. **Deterministic Evaluation**: Fixed seeds, versioned metrics, reproducible scoring

#### When to Use Req2Run

- âœ… Evaluating end-to-end implementation capability from requirements
- âœ… Assessing production readiness of generated code
- âœ… Measuring non-functional requirements compliance
- âœ… Benchmarking cost-efficiency of AI systems
- âŒ Quick function-level testing (use HumanEval/MBPP)
- âŒ Bug fixing in existing code (use SWE-bench)

### Contributing

1. Fork this repository
2. Create a feature branch (`git checkout -b feature/NewProblem`)
3. Commit your changes (`git commit -m 'Add new problem category'`)
4. Push to the branch (`git push origin feature/NewProblem`)
5. Create a Pull Request

See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for details.

### License

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.

### Contact

- Project Lead: ITdo Inc. Japan
- Email: contact@itdo.jp
- Issue Tracker: [GitHub Issues](https://github.com/itdojp/req2run-benchmark/issues)

### Acknowledgments

This project is made possible by contributions from the AI/LLM community.

---

<a id="japanese"></a>
## æ—¥æœ¬èª

**è¦æ±‚ä»•æ§˜ã‹ã‚‰å®Ÿå‹•ã‚³ãƒ¼ãƒ‰ã¾ã§AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/itdojp/req2run-benchmark)
[![Status](https://img.shields.io/badge/status-active-green.svg)]()

### æ¦‚è¦

Req2Runï¼ˆRequirements to Running Codeï¼‰ã¯ã€AI/LLMã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…èƒ½åŠ›ã‚’å®šé‡çš„ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚è©³ç´°ãªè¦æ±‚ä»•æ§˜ã‹ã‚‰å®Ÿå‹•ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€è‡ªå‹•è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

### ç‰¹å¾´

- ğŸ¯ **åŒ…æ‹¬çš„ãªå•é¡Œã‚»ãƒƒãƒˆ**: 35å•é¡Œã€Web APIã€æš—å·åŒ–ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãªã©16ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒª
- ğŸ¤– **å®Œå…¨è‡ªå‹•è©•ä¾¡**: äººé–“ã®ä»‹å…¥ãªã—ã§ç”Ÿæˆã‹ã‚‰è©•ä¾¡ã¾ã§å®Ÿè¡Œ
- ğŸ“Š **å®šé‡çš„ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: æ©Ÿèƒ½å……è¶³ç‡ã€æ€§èƒ½ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰å“è³ªã‚’æ¸¬å®š
- ğŸ”§ **æ¨™æº–åŒ–ã•ã‚ŒãŸç’°å¢ƒ**: Docker/Kubernetesä¸Šã§ã®çµ±ä¸€å®Ÿè¡Œç’°å¢ƒ
- ğŸ“ˆ **é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«**: Basic (1)ã€Intermediate (8)ã€Advanced (17)ã€Expert (9)ã®4æ®µéš
- ğŸŒ **å®Œå…¨ãªå›½éš›åŒ–å¯¾å¿œ**: å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè‹±èªã¨æ—¥æœ¬èªã§åˆ©ç”¨å¯èƒ½

### ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

#### å‰ææ¡ä»¶

- Python 3.9+ (3.11æ¨å¥¨)
- Docker 24.0+ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€æ¨å¥¨)
- Git

#### ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/itdojp/req2run-benchmark.git
cd req2run-benchmark

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚¯ã‚¤ãƒƒã‚¯ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# Linux/Mac:
./scripts/setup-env.sh

# Windows PowerShell:
.\scripts\setup-env.ps1

# Windows CMD:
scripts\setup-env.bat
```

è©³ç´°ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã¯[ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰](docs/ENVIRONMENT_SETUP.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

#### Dockerã®ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰

```bash
# ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
docker build -t req2run-benchmark .

# Dockerã‚³ãƒ³ãƒ†ãƒŠã§å®Ÿè¡Œ
docker run -it -v $(pwd):/workspace req2run-benchmark bash

# ã¾ãŸã¯é–‹ç™ºç”¨ã«docker-composeã‚’ä½¿ç”¨
docker-compose -f docker-compose.dev.yml up
```

#### æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆ
python -m venv venv

# ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
venv\Scripts\activate.bat  # Windows

# ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

ä¾å­˜é–¢ä¿‚ã®å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€[ä¾å­˜é–¢ä¿‚ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](docs/DEPENDENCY_TROUBLESHOOTING.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

#### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```bash
# å˜ä¸€å•é¡Œã®è©•ä¾¡å®Ÿè¡Œ
python -m req2run evaluate --problem WEB-001 --submission ./submissions/my_solution

# ãƒãƒƒãƒè©•ä¾¡ã®å®Ÿè¡Œ
python -m req2run batch-evaluate --difficulty intermediate --output ./results

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
python -m req2run report --results ./results --format html
```

### å•é¡Œã‚«ãƒ†ã‚´ãƒª

| ã‚«ãƒ†ã‚´ãƒª | èª¬æ˜ | å•é¡Œæ•° |
|---------|------|--------|
| `web_api` | RESTful APIå®Ÿè£… | 3 |
| `cli_tool` | CLIãƒ„ãƒ¼ãƒ«é–‹ç™º | 2 |
| `network_protocol` | ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ« | 2 |
| `cryptography` | æš—å·åŒ–ãƒ„ãƒ¼ãƒ« | 2 |
| `data_processing` | ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | 2 |
| `system_utility` | ã‚·ã‚¹ãƒ†ãƒ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ | 2 |
| `machine_learning` | ML ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ | 1 |
| `database` | ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Ÿè£… | 2 |

### è©•ä¾¡ãƒ•ãƒ­ãƒ¼

```mermaid
graph LR
    A[è¦æ±‚ä»•æ§˜] --> B[AIç”Ÿæˆ]
    B --> C[ãƒ“ãƒ«ãƒ‰]
    C --> D[ãƒ‡ãƒ—ãƒ­ã‚¤]
    D --> E[ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ]
    E --> F[ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†]
    F --> G[ã‚¹ã‚³ã‚¢ç®—å‡º]
    G --> H[ãƒ¬ãƒãƒ¼ãƒˆ]
```

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
req2run-benchmark/
â”œâ”€â”€ problems/           # å•é¡Œå®šç¾©ï¼ˆYAMLï¼‰
â”‚   â”œâ”€â”€ basic/         # åŸºç¤ãƒ¬ãƒ™ãƒ«å•é¡Œ
â”‚   â”œâ”€â”€ intermediate/  # ä¸­ç´šãƒ¬ãƒ™ãƒ«å•é¡Œ
â”‚   â”œâ”€â”€ advanced/      # ä¸Šç´šãƒ¬ãƒ™ãƒ«å•é¡Œ
â”‚   â””â”€â”€ expert/        # ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«å•é¡Œ
â”œâ”€â”€ evaluation/        # è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
â”‚   â”œâ”€â”€ harness/      # ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒã‚¹
â”‚   â”œâ”€â”€ metrics/      # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
â”‚   â””â”€â”€ reports/      # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â”œâ”€â”€ infrastructure/    # ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®š
â”‚   â”œâ”€â”€ docker/       # Dockerã‚³ãƒ³ãƒ†ãƒŠ
â”‚   â”œâ”€â”€ kubernetes/   # K8sãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ
â”‚   â””â”€â”€ terraform/    # IaCè¨­å®š
â”œâ”€â”€ scripts/          # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ tests/            # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
â””â”€â”€ docs/             # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
```

### è©•ä¾¡åŸºæº–

å„å•é¡Œã¯ä»¥ä¸‹ã®åŸºæº–ã§è©•ä¾¡ã•ã‚Œã¾ã™ï¼š

- **æ©Ÿèƒ½è¦ä»¶å……è¶³ç‡** (30-40%)
- **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹é€šéç‡** (20-30%)
- **æ€§èƒ½è¦ä»¶é”æˆ** (10-20%)
- **ã‚³ãƒ¼ãƒ‰å“è³ª** (10-20%)
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£** (10-20%)

åˆæ ¼åŸºæº–ï¼šç·åˆã‚¹ã‚³ã‚¢ â‰¥ 70%

### APIåˆ©ç”¨

```python
from req2run import Evaluator, Problem

# å•é¡Œã®ãƒ­ãƒ¼ãƒ‰
problem = Problem.load("WEB-001")

# è©•ä¾¡å™¨ã®åˆæœŸåŒ–
evaluator = Evaluator(
    problem=problem,
    environment="docker",
    timeout=3600
)

# è©•ä¾¡å®Ÿè¡Œ
result = evaluator.evaluate(
    submission_path="./my_solution",
    verbose=True
)

# çµæœã®å–å¾—
print(f"Score: {result.score}")
print(f"Status: {result.status}")
```

### ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®é•ã„

Req2Runã¯ã€AIã‚³ãƒ¼ãƒ‰ç”Ÿæˆè©•ä¾¡ã®ä¸­ã§ç‹¬è‡ªã®ãƒ‹ãƒƒãƒã‚’åŸ‹ã‚ã¦ã„ã¾ã™ï¼š

| ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ | ç„¦ç‚¹ | è©•ä¾¡æ–¹æ³• |
|------------|------|---------|
| **HumanEval/MBPP** | é–¢æ•°ãƒ¬ãƒ™ãƒ«ã®çŸ­ã„å•é¡Œ | Pass@k ãƒ¡ãƒˆãƒªãƒƒã‚¯ |
| **SWE-bench** | æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å•é¡Œä¿®æ­£ | è§£æ±ºç‡ï¼ˆ%ï¼‰ |
| **Req2Run** | è¦æ±‚ä»•æ§˜ â†’ æ–°è¦å®Ÿè£… â†’ æœ¬ç•ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ | æ©Ÿèƒ½ + NFRï¼ˆæ€§èƒ½/ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£/å“è³ªï¼‰ |

**ä¸»ãªå·®åˆ¥åŒ–è¦å› ï¼š**
- **ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰è©•ä¾¡**ï¼šè¦æ±‚ä»•æ§˜ã‹ã‚‰æœ¬ç•ªç’°å¢ƒå¯¾å¿œã‚³ãƒ¼ãƒ‰ã¾ã§
- **éæ©Ÿèƒ½è¦ä»¶**ï¼šæ€§èƒ½ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ã‚³ãƒ¼ãƒ‰å“è³ªã‚’ç¬¬ä¸€ç´šãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦æ‰±ã†
- **çµ±ä¸€ç’°å¢ƒ**ï¼šDocker/Kubernetesæ¨™æº–åŒ–ã«ã‚ˆã‚Šå†ç¾æ€§ã‚’ä¿è¨¼
- **å®Ÿè·µçš„ç„¦ç‚¹**ï¼šå®Ÿéš›ã®é–‹ç™ºã‚¿ã‚¹ã‚¯ã‚’è¡¨ç¾ã™ã‚‹å•é¡Œè¨­å®š

### è²¢çŒ®æ–¹æ³•

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/NewProblem`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add new problem category'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/NewProblem`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

è©³ç´°ã¯ [CONTRIBUTING.md](docs/CONTRIBUTING.md) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### é€£çµ¡å…ˆ

- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ¼ãƒ€ãƒ¼: ITdo Inc. Japan
- Email: contact@itdo.jp
- Issue Tracker: [GitHub Issues](https://github.com/itdojp/req2run-benchmark/issues)

### è¬è¾

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€AI/LLMã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è²¢çŒ®ã«ã‚ˆã‚Šå®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

---

**Note**: ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ç¶™ç¶šçš„ã«æ”¹å–„ã•ã‚Œã¦ã„ã¾ã™ã€‚æœ€æ–°æƒ…å ±ã¯ [ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆ](https://github.com/itdojp/req2run-benchmark/releases) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚ | This benchmark is continuously being improved. Check [Release Notes](https://github.com/itdojp/req2run-benchmark/releases) for the latest updates.
