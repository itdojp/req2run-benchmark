id: DATA-011
title: "ETL Pipeline with Change Data Capture (CDC)"
difficulty: advanced
category: data_processing
languages:
  - python
  - java
  - go
  - scala
  - rust

requirements:
  functional:
    - id: FR-001
      description: "The system MUST capture database changes in real-time using CDC"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-002
      description: "The system MUST transform data according to configurable rules"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-003
      description: "The system MUST support multiple source and sink connectors"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-004
      description: "The system MUST handle schema evolution gracefully"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-005
      description: "The system MUST maintain data lineage tracking"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-006
      description: "The system MUST implement idempotent transformations"
      priority: MUST
      validation:
        type: unit_test
    
    - id: FR-007
      description: "The system MUST support incremental and full loads"
      priority: MUST
      validation:
        type: integration_test
    
    - id: FR-008
      description: "The system MUST provide data quality checks"
      priority: SHOULD
      validation:
        type: integration_test
    
    - id: FR-009
      description: "The system SHOULD support data deduplication"
      priority: SHOULD
      validation:
        type: integration_test
    
    - id: FR-010
      description: "The system MAY support custom transformation plugins"
      priority: MAY
      validation:
        type: integration_test
  
  non_functional:
    performance:
      p95_latency_ms: 500
      p99_latency_ms: 2000
      throughput_rps: 10000
      cpu_limit: "4000m"
      memory_limit: "8Gi"
      max_lag_seconds: 30
    
    security:
      network_egress: "ALLOW"
      secrets_in_code: "FORBIDDEN"
      authentication: "REQUIRED"
      encryption: "TLS_REQUIRED"
      data_masking: "REQUIRED"
    
    quality:
      max_cyclomatic_complexity: 15
      min_test_coverage: 85
      documentation_required: true
      type_hints_required: true

constraints:
  allowed_packages:
    - "debezium"
    - "kafka-connect"
    - "airbyte"
    - "apache-nifi"
    - "dagster"
    - "prefect"
    - "airflow"
    - "dbt"
  
  disallowed_packages: []
  
  disallowed_syscalls:
    - "fork"
    - "exec"
  
  resource_limits:
    max_cpu_cores: 8
    max_memory_gb: 16
    max_disk_gb: 200
    max_network_bandwidth_mbps: 500
  
  time_limits:
    generation_minutes: 45
    execution_minutes: 30

artifacts:
  entrypoint: "src/main"
  dockerfile: "Dockerfile"
  healthcheck: "/health"
  config_files:
    - "config/cdc.yaml"
    - "config/transformations.yaml"
    - "config/connectors.yaml"

tests:
  unit: "tests/unit/"
  integration: "tests/integration/"
  performance: "tests/performance/"
  test_data:
    input_files:
      - "test_data/source_schema.sql"
      - "test_data/change_events.json"
      - "test_data/transformation_rules.yaml"
    expected_outputs:
      - "test_data/expected/transformed_data.json"
      - "test_data/expected/lineage.json"

metrics:
  weights:
    functional_coverage: 0.35
    pass_rate: 0.25
    performance: 0.25
    code_quality: 0.10
    security: 0.05
  
  thresholds:
    min_functional_coverage: 90
    min_pass_rate: 95
    min_performance_score: 85

pass_criteria:
  min_total_score: 0.85
  mandatory_requirements:
    - "FR-001"
    - "FR-002"
    - "FR-003"
    - "FR-004"
    - "FR-005"
    - "FR-006"
    - "FR-007"
  forbidden_violations:
    - "critical_security"
    - "runtime_failure"
    - "data_corruption"
    - "data_loss"

metadata:
  author: "Req2Run Team"
  created_date: "2024-01-21"
  last_modified: "2024-01-21T11:00:00Z"
  version: "1.0.0"
  tags:
    - "etl"
    - "cdc"
    - "data-pipeline"
    - "debezium"
    - "transformation"
    - "data-integration"
  references:
    - title: "Change Data Capture"
      url: "https://debezium.io/documentation/reference/stable/tutorial.html"
    - title: "ETL Best Practices"
      url: "https://docs.airbyte.com/understanding-airbyte/etl-pipeline-guide"
    - title: "Data Lineage"
      url: "https://www.ibm.com/topics/data-lineage"
  notes: |
    This problem tests the ability to implement a comprehensive ETL pipeline
    with CDC capabilities, schema evolution, and data lineage tracking.